---
title: "This American R"
author: "Chris Cote"
date: '2020-02-14'
slug: this-american-r
categories: Text
---



<div id="motivation" class="section level2">
<h2>Motivation</h2>
<p>I love This American Life. I thought it would be a fun corpus to look at and do some text analysis on. I’m still working on getting a public and updated version of this dataset up, but for now, let’s just look at what we can see!</p>
</div>
<div id="setup" class="section level2">
<h2>Setup</h2>
<p>Load tidyverse, set theme, read in local file…</p>
<pre class="r"><code>library(tidyverse)

theme_cc &lt;- theme(panel.grid = element_line(color = &quot;gray90&quot;),
        panel.background = element_blank(),
        plot.background = element_blank(),
        plot.title = element_text(hjust = 0.5))

tal &lt;- read_csv(&quot;~/Documents/HKS/rtutorial/data/this_american_life/tal_complete.csv&quot;)</code></pre>
</div>
<div id="cleaning" class="section level2">
<h2>Cleaning</h2>
<p>Do some preliminary cleaning, taking out carriage return characters, getting rid of stopwords – all on first 100 episodes only</p>
<pre class="r"><code>tal_tidy &lt;- tal %&gt;%  slice(1:100) %&gt;% 
  tidytext::unnest_tokens(&quot;word&quot;, content) %&gt;% 
  mutate(title = str_replace_all(title, &quot;\\\n&quot;, &quot; &quot;) %&gt;% 
           str_replace(., &quot;Transcript.+Originally aired.+&quot;, &quot;&quot;)) %&gt;% 
  anti_join(tidytext::stop_words)</code></pre>
<p>Let’s create a file that gives us the tf_idf of the whole corpus.</p>
<p>Read more in the fantastic [Tidy Text Mining] book (<a href="https://www.tidytextmining.com/tfidf.html" class="uri">https://www.tidytextmining.com/tfidf.html</a>)</p>
<p><a href="https://juliasilge.com/blog/introducing-tidylo/">(oops! … )</a></p>
<pre class="r"><code>tal_tf_idf &lt;- tal_tidy  %&gt;% 
  select(title, word) %&gt;% 
  group_by(title) %&gt;% 
  count(word, sort = TRUE) %&gt;% 
  ungroup() %&gt;% 
  tidytext::bind_tf_idf(word, title, n)</code></pre>
<p>Using the tf idf dataset, let’s look at the most important words in the first 50 episodes ever.</p>
<pre class="r"><code>tal_tf_idf %&gt;% 
  group_by(title) %&gt;% 
  arrange(-tf_idf) %&gt;% 
  slice(1:10) %&gt;% 
  summarise(top_words = str_c(word, collapse = &quot;, &quot;)) %&gt;% 
  ungroup() %&gt;% 
  left_join(tal_tidy %&gt;% 
  distinct(title, air_date, show_number)) %&gt;% 
  arrange(air_date) %&gt;% 
  mutate(title_words = str_c(title, top_words, sep = &quot;: &quot;)) %&gt;% 
  ggplot() + 
  geom_text(aes(-show_number, -5, label = title_words), size = 3, hjust = 0) + 
  # scale_x_date(date_labels = &quot;%y-%m-%d&quot;) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.background = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
    scale_y_continuous(limits = c(-6, 6)) +
  coord_flip() + 
  labs(x = NULL, y = NULL, title = &quot;Episode Title and Unique Words&quot;) +
  NULL</code></pre>
<p><img src="/post/2020-02-14-this-american-r-blog_files/figure-html/unnamed-chunk-3-1.png" width="624" /></p>
<p>OK now let’s look at the words that are most unique per episode and most frequently occuring overall</p>
<p>Hmmm… Bob Dole and Frank Sinatra! Ira has some questions to answer.</p>
<pre class="r"><code>tt &lt;- tal_tf_idf %&gt;% 
  arrange(-tf_idf) %&gt;% 
  group_by(word) %&gt;% 
  mutate(total_n = sum(n)) %&gt;% 
  ungroup()

tt %&gt;% 
  group_by(word) %&gt;% 
  mutate(total_shows = n()) %&gt;% 
  ungroup() %&gt;% 
  filter(tf_idf &gt; 0.035,
         total_shows &gt; 1) %&gt;% 
  ggplot(aes(tf_idf, total_n)) + 
  geom_point(aes(size = total_shows, alpha = tf_idf), shape = 21) +
  ggrepel::geom_text_repel(aes(label = word), size = 3) +
  scale_y_log10() +
  theme_cc</code></pre>
<p><img src="/post/2020-02-14-this-american-r-blog_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<div id="how-frequently-is-david-sedaris-on-tal" class="section level3">
<h3>How frequently is David Sedaris on TAL?</h3>
<p>Frequent listerns know that David Sedaris is a frequent guest on This American Life. The question is: how frequent? Sometimes it feels like he’s on every 10 episodes. Is this true?</p>
<p>The chart below shows time between each episode that features David Sedaris.</p>
<pre class="r"><code>tal %&gt;% filter(str_detect(content, regex(&quot;sedaris&quot;,ignore_case = TRUE))) %&gt;%   tidytext::unnest_tokens(&quot;word&quot;, content) %&gt;% 
  filter(word == &quot;sedaris&quot;) %&gt;% 
  group_by(show_number, air_date) %&gt;% 
  count() %&gt;% 
  ungroup() %&gt;% 
  arrange(air_date) %&gt;% 
  mutate(time_between = as.numeric(air_date - lag(air_date))) %&gt;% 
  ggplot(aes(show_number, time_between)) +
  geom_point() +
  geom_line() +
  theme_cc +
  labs(title = &quot;Where&#39;s David?&quot;, x = &quot;Show Number&quot;, y = &quot;Days since Last Sedaris Appearance&quot;)</code></pre>
<p><img src="/post/2020-02-14-this-american-r-blog_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>tal %&gt;% filter(str_detect(content, regex(&quot;sedaris&quot;,ignore_case = TRUE))) %&gt;%    
  tidytext::unnest_tokens(&quot;word&quot;, content) %&gt;% 
  filter(show_number &lt; 50) %&gt;% 
  mutate(title = str_replace_all(title, &quot;\\\n&quot;, &quot; &quot;) %&gt;% 
           str_replace(., &quot;Transcript.+Originally aired.+&quot;, &quot;&quot;)) %&gt;% 
  anti_join(tidytext::stop_words) %&gt;% 
  select(title, word) %&gt;% 
  group_by(title) %&gt;% 
  count(word, sort = TRUE) %&gt;% 
  ungroup() %&gt;% 
  tidytext::bind_tf_idf(word, title, n) %&gt;% 
  group_by(title) %&gt;% 
  top_n(10, tf_idf) %&gt;% 
  ungroup() %&gt;% 
  mutate(title = str_wrap(title, 30)) %&gt;% 
  ggplot() + geom_col(aes(fct_reorder(word, tf_idf), tf_idf,  fill = word), show.legend = FALSE) +
  facet_wrap(~title, scales = &quot;free_y&quot;) +
  coord_flip() + 
  theme(legend.position = &quot;none&quot;) +
  theme_cc + 
  labs(x = NULL,y = NULL, title = &quot;Top words in Episodes featuring David Sedaris&quot;) +
  theme(strip.background = element_blank())</code></pre>
<pre><code>## Joining, by = &quot;word&quot;</code></pre>
<p><img src="/post/2020-02-14-this-american-r-blog_files/figure-html/unnamed-chunk-6-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
</div>
